\documentclass[nobib, a4paper, notoc, twoside, justified, openany]{tufte-book}
%% XXX the openany option avoids abnoxious blank pages between chapters

\RequirePackage{filecontents}


\usepackage{amsmath,amssymb,amsfonts,amsbsy,amsthm}

\usepackage{bibentry}

\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{url}
\usepackage{makeidx}
\usepackage{sectsty}
\usepackage[sectionbib]{natbib}
\usepackage[sectionbib]{chapterbib}
\usepackage[toc, xindy]{glossaries}
\usepackage{minitoc}
% \usepackage{titletoc}
\usepackage{booktabs}
\usepackage{color}
\usepackage{framed}
\usepackage{upgreek}
\usepackage[absolute]{textpos}

\usepackage{caption}

\usepackage[titles]{tocloft}
% \setlength\cftbeforefigskip{50pt}
\setlength\cftbeforechapskip{20pt}
\setlength\cftbeforesecskip{10pt}
\renewcommand{\cftchapfont}{\sffamily \color{msblue} \huge}
\renewcommand{\cftsecfont}{\it \sffamily \Large}
\renewcommand{\cftsubsecfont}{\sffamily \large}

% \usepackage{mdframed}
% \usepackage{titletoc}

% \definecolor{secnum}{RGB}{13,151,225}
% \definecolor{ptcbackground}{RGB}{212,237,252}
% \definecolor{ptctitle}{RGB}{0,177,235}

% \titlecontents{lsection}
%   [5.8em]{\sffamily}
%   {\color{secnum}\contentslabel{2.3em}\normalcolor}{}
%   {\titlerule*[1000pc]{.}\contentspage\\\hspace*{-5.8em}\vspace*{5pt}%
%     \color{white}\rule{\dimexpr\textwidth-15.5pt\relax}{1pt}}

% \newcommand\PartialToC{%
% \startcontents[chapters]%
% \begin{mdframed}[backgroundcolor=ptcbackground,hidealllines=true]
% \printcontents[chapters]{l}{1}{\colorbox{ptctitle}{%
%   \parbox[t]{\dimexpr\textwidth-2\fboxsep\relax}{%
%     \strut\color{white}\bfseries\sffamily\makebox[5em]{%
%       Chapter~\thechapter\hfill}Contents}}\vskip5pt}
% \end{mdframed}%
% }

% \renewcommand{\cftchapterfont}{\normalfont\sffamily}   
% \renewcommand{\cftsectionfont}{\normalfont\sffamily}


\definecolor{shadecolor}{RGB}{211, 211, 211}

\usepackage{listings}
\usepackage[utf8]{inputenc}
\pagestyle{myheadings}
% fonts
\usepackage{libertine}
\usepackage[libertine]{newtxmath}
\usepackage[T1]{fontenc}
\usepackage[tikz]{bclogo}
\usepackage{fourier-orns}


\setcaptionfont{\normalsize}
\setmarginnotefont{\normalsize}
\setsidenotefont{\normalsize}


\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{1}
\graphicspath{{figures/}}
\definecolor{msblue}{rgb}{.204,.353,.541}
\newcommand{\red}{\color{red}}
\newcommand{\blue}{\color{blue}}

\usepackage{algorithm,algorithmicx,algpseudocode}
\usepackage[svgnames]{xcolor} % Specify colors by their 'svgnames', for a full list of all colors available see here: http://www.latextemplates.com/svgnames-colors
\usepackage{svg}
\usepackage{mdframed}
\usepackage{titletoc}
\usepackage{longtable}
\usepackage{framed}
\usepackage{xr}

\DeclareMathOperator*{\vecop}{vec}
\def\RR{{\mathbb R}}
\def\YY{{\mathbf Y}}
\def\bfbeta{{\boldsymbol \beta}}
\def\bvarepsilon{{\boldsymbol \varepsilon}}
\def\bfvarepsilon{{\boldsymbol \varepsilon}}
\def\bfomega{{\boldsymbol \upomega}}
\def\bfalpha{{\boldsymbol \upalpha}}
\def\btheta{\boldsymbol \theta}
\newcommand{\balpha}{\boldsymbol \alpha}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\sign}{sign}
\newcommand{\dive}{\textrm{div}}

\def\NN{\mathbb N}
\def\CC{\mathbb C}
\providecommand{\B}[1]{\mathbf{#1}}
\def \lb {{\langle}}
\def \rb {{\rangle}}
\def\XX{\mathcal{X}}
\def\EE{\mathbb{E}}
\def\Rpsi{\mathcal{R}_n^{\psi}}

\definecolor{color1}{RGB}{251,180,174}
\definecolor{color2}{RGB}{179,205,227}
\definecolor{color3}{RGB}{204,235,197}
\definecolor{mslightblue}{rgb}{.31,.506,.741}


\newtheorem{lemma}{Lemma}
\newtheorem{result}{Result}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}


\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\ttfamily}}}
\makeatother
\urlstyle{leo}

% chapter format
\titleformat{\chapter}%
  {\Huge \sffamily \itshape\color{msblue}}% format applied to label+text
  {\llap{\colorbox{msblue}{\parbox{1.5cm}{\hfill\itshape\Huge\color{white}\thechapter}}}}% label
  {2pt}% horizontal separation between label and title body
  {}% before the title body
  []% after the title body

% % section format
% \titleformat{\section}%
%   {\normalfont\LARGE\itshape\color{msblue}}% format applied to label+text
%   {\llap{\colorbox{orange}{\parbox{1.5cm}{\hfill\color{white}\thesection}}}}% label
%   {1em}% horizontal separation between label and title body
%   {}% before the title body
%   []% after the title body

% % subsection format
% \titleformat{\subsection}%
%   {\normalfont\large\itshape\color{blue}}% format applied to label+text
%   {\llap{\colorbox{blue}{\parbox{1.5cm}{\hfill\color{white}\thesubsection}}}}% label
%   {1em}% horizontal separation between label and title body
%   {}% before the title body
%   []% after the title body



\newcommand{\blankpage}{\newpage\hbox{}\thispagestyle{empty}\newpage}

%%% Hack to allow page-wide figures. Just use \begin{pagefigure}...\end{pagefigure}
\RequirePackage{etoolbox}
\makeatletter
\newif\if@tufte@margtab\@tufte@margtabfalse
\AtBeginEnvironment{margintable}{\@tufte@margtabtrue}
\AtEndEnvironment{margintable}{\@tufte@margtabfalse}
\newcommand{\classiccaptionstyle}{%
    \long\def\@caption##1[##2]##3{%
        \par
        \addcontentsline{\csname ext@##1\endcsname}{##1}%
        {\protect\numberline{\csname the##1\endcsname}{\ignorespaces ##2}}%
        \begingroup
        \@parboxrestore
        \if@minipage
        \@setminipage
        \fi
        \normalsize
        \@makecaption{\csname fnum@##1\endcsname}{\ignorespaces ##3}\par
        \endgroup}
    \long\def\@makecaption##1##2{%
        \vskip\abovecaptionskip
        \sbox\@tempboxa{\@tufte@caption@font##1: ##2}%
        \ifdim \wd\@tempboxa >\hsize
        \@tufte@caption@font\if@tufte@margtab\@tufte@caption@justification\fi##1: ##2\par
        \else
        \global \@minipagefalse
        \hb@xt@\hsize{\hfil\box\@tempboxa\hfil}%
        \fi
        \vskip\belowcaptionskip}
    %   \setcaptionfont{\normalfont}
    \let\caption\@tufte@orig@caption%
    \let\label\@tufte@orig@label}
\makeatother

\newenvironment{pagefigure}{%
    \begin{figure*}[!htbp]
    \classiccaptionstyle
  }{\end{figure*}}

\allsectionsfont{\rm \bf \color{msblue} \sffamily}


\title{Enhancement of functional brain connectome analysis by the use of deformable
models in the estimation of spatial decompositions of the brain images}
\author{Elvis Dohmatob}


\makeglossaries

% Generates the index
\makeindex









% \DeclareMathOperator{\argmin}{argmin}
\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\soft}{soft}
\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator{\Prox}{Prox}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\conv}{conv}
\DeclareMathOperator{\cont}{cont}
\DeclareMathOperator{\inte}{int }

\def\Id{\mathbf{I}}
\def\1{\mathbf{1}}
\def\X{\mathbf{X}}
\def\U{\mathbf{U}}
\def\V{\mathbf{V}}
\def\v{\mathbf{v}}
\def\u{\mathbf{u}}
\def\Y{\mathbf{Y}}
\def\y{\mathbf{y}}
\def\A{\mathbf{A}}
\def\I{\mathbf{I}}
% \def\B{\mathbf{B}}
\def\a{\mathbf{a}}
\def\s{\mathbf{s}}
\def\r{\mathbf{r}}
\def\x{\mathbf{x}}
\def\K{\mathbf{K}}
\def\z{\mathbf{z}}
\def\w{\mathbf{w}}
\def\p{\mathbf{p}}
\def\G{\mathbf{G}}
\def\b{\mathbf{b}}

\begin{document}
% \dominitoc

\begin{titlepage}
\begin{fullwidth}
\begin{center}

\begin{textblock}{4}(1.5,0.5)
\begin{figure}
\includegraphics[width=\linewidth]{figures/unips_logo.png}
\end{figure}
\end{textblock}


\begin{textblock}{4.8}(10,0.5)
\begin{figure}
\includegraphics[width=\linewidth]{figures/logotheque-inriascientifiquefr.eps}
\end{figure}
\end{textblock}

% \begin{textblock}
% \includegraphics[width=0.4\linewidth]{figures/logotheque-inriascientifiquefr.eps}
% \end{textblock}


\vspace*{30pt}
\textsc{{\huge université paris-saclay} \\
% {\vspace{10pt} \LARGE école doctorale informatique, \\télécommunications et électronique} \\
{\vspace{10pt} \LARGE doctoral school  of computer science, Paris-Sud}  \\
{\vspace{10pt}\LARGE prepared at parietal team - inria saclay} \\
}
% \textsc{\Large PhD thesis}\\[0.5cm]

\vspace{10pt}

% Statistical learning methods applied to fMRI: from BOLD timeseries
% to decoding. 

% Feature extraction and supervised learning on fMRI: From practice to theory

\vspace{2pc}
{ \Huge
{\color{msblue} {Enhancement of functional brain connectome analysis by the use of deformable
models in the estimation of spatial decompositions of the brain images}} \\[0.5cm]
% {\color{msblue} {Estimation de variables et apprentissage supervisé en IRMf: de la pratique à la théorie}} \\[0.5cm]
% {\it {from practice to theory}} \\[1.2cm]
% {\it multi-voxel pattern analysis.}
}


% \vspace{4pc}
% {\Large\aldineleft} \\
% \vspace{4pc}


\vspace{3pc}
{\Huge \it Elvis Dohmatob} \\

\vspace{3pc}



{\LARGE A dissertation submitted to the department of computer science of the Universit\'e Paris-Saclay, in partial fulfillment
  \\of the requirements for the degree of \\  \vspace{10pt} 
  \textbf{Doctor of Philosophy}.}\\
\vspace{1pc}

{\LARGE Supervised by {Bertrand Thirion} and {Gael Varoquaux}.}

% \vspace{1pc}

\vspace{2pc}
{\LARGE Defended publicly the 20th of September 2017 in front of a jury composed of:}
\vspace{2pc}


{\LARGE
\begin{tabular}{lll}
\vspace{1pc}
\textbf{Advisors} & Bertrand Thirion & INRIA / CEA, Saclay, France \\
\vspace{1pc}
 & Gael Varoquaux & INRIA / CEA, Saclay, France \\
\vspace{1pc}
  \textbf{Reviewers} & John Ashburner  & UCL, London, UK  \\
  \vspace{1pc}  
& Gabriel Peyr\'e  & Universit\'e Paris-Dauphine, France  \\  \\
  \vspace{1pc}
\textbf{Examiners} & Marc Schoenauer & INRIA,  Saclay, France \\
  \vspace{1pc}
 & Moritz Grosse-Wentrup  & MPI, Tuebingen, Germany \\  
\vspace{1pc}
\end{tabular}
}


\end{center}
\end{fullwidth}
\end{titlepage}


\begin{titlepage}
\begin{fullwidth}
\begin{center}

\begin{textblock}{4}(1.5,0.5)
\begin{figure}
\includegraphics[width=\linewidth]{figures/unips_logo.png}
\end{figure}
\end{textblock}


\begin{textblock}{4.8}(10,0.5)
\begin{figure}
\includegraphics[width=\linewidth]{figures/logotheque-inriascientifiquefr.eps}
\end{figure}
\end{textblock}

% \begin{textblock}
% \includegraphics[width=0.4\linewidth]{figures/logotheque-inriascientifiquefr.eps}
% \end{textblock}


\vspace*{30pt}
\textsc{{\huge université paris-saclay} \\
 {\vspace{10pt} \LARGE école doctorale informatique, \\ Paris-Sud} \\
{\vspace{10pt}\LARGE équipe parietal - inria saclay}}

% \textsc{\Large PhD thesis}\\[0.5cm]

\vspace{10pt}

% Statistical learning methods applied to fMRI: from BOLD timeseries
% to decoding. 

% Feature extraction and supervised learning on fMRI: From practice to theory

\vspace{2pc}
{ \Huge
{\color{msblue} {Amelioration de connectivit\'e fonctionnelle par utilisation de mod\`eles deformables dans l'estimation de decompositions spatiales des images de cerveau}} \\[0.5cm]
% {\it {from practice to theory}} \\[1.2cm]
% {\it multi-voxel pattern analysis.}
}


% \vspace{4pc}
% {\Large\aldineleft} \\
% \vspace{4pc}


\vspace{3pc}
{\Huge \it Elvis Dohmatob} \\

\vspace{3pc}



{\LARGE Thèse de doctorat pour obtenir le grade de \ \\[1ex]
{\bf DOCTEUR de l'UNIVERSIT\'E PARIS-SACLAY} \ \\
}
\vspace{1pc}

{\LARGE Dirig\'ee par {Bertrand Thirion} et {Gael Varoquaux}.}

\vspace{1pc}


{\LARGE Présentée et soutenue publiquement le 20 Septembre 2017 devant \\ \vspace{10pt} un jury composé de:}

\vspace{1pc}

{\LARGE
\begin{tabular}{lll}
\vspace{1pc}
\textbf{Directeurs} & Bertrand Thirion & INRIA / CEA, Saclay, France \\
\vspace{1pc}
 & Gael Varoquaux & INRIA / CEA, Saclay, France \\
\vspace{1pc}
  \textbf{Rapporteurs} & John Ashburner  & UCL, London, UK  \\
  \vspace{1pc}  
& Gabriel Peyr\'e  & Universit\'e Paris-Dauphine, France  \\  \\
  \vspace{1pc}
\textbf{Examinateurs} & Marc Schoenauer & INRIA,  Saclay, France \\
  \vspace{1pc}
 & Moritz Grosse-Wentrup  & MPI, Tuebingen, Germany \\  
\end{tabular}
}

\end{center}
\end{fullwidth}
\end{titlepage}


% >  - 1. Introduction to fMRI
% >
% >     Brain functional architecture
% >     Neural coding of mental processes
% >     Functional Neuroimaging modalities: EEG, MEG , fMRI etc. (really brief on other modalities)
% >     fMRI signals : history, what we measure, how, MRI basics
% >
% >  - 2. From BOLD signal to activation maps (good transition + good)
% >
% >     Preprocessing of fMRI
% >     The BOLD signal: linear time invariant assumption
% >     Models of the HRF (Glover, FIR, etc.)
% >     The GLM
% >     Statistical Univariate tests (contrasts)
% >
% >  - 3. Beyond the canonical HRF
% >
% >     FIR models
% >     Bayesian JDE approaches
% >     R1-GLM
% >     R1 Optimization (algorithm)
% >       Smooth Optimization: First order, Quasi-Newton and Newton methods
% >       Benchmarks
% >       A tensor formulation of the GLM (maybe for appendix) XXX : keep it here
% >
% >  - 4. Encoding and Decoding models
% >
% >     Decoding and decoding
% >       Model selection and validation
% >       Dimension reduction
% >       Regularization
% >       Sparsity
% >
% >    Enhanced sensitivity via HRF estimation
% >      Experimental Validation
% >
% >  - 5. Prediction with ordinal labels
% >
% >     Ordinal targets in decoding models
% >     Ranking vs Ordinal Regression
% >     Learning to rank from medical imaging datasets
% >
% >  - 6. Surrogate loss functions for ordinal labels
% >
% >     Design of surrogate loss functions
% >     Consistency of Ranking (Duchi 2010)
% >     Consistency of Ordinal Regression


%\newpage\null\thispagestyle{empty}
% \newpage
% \vspace*{\fill}

% {\section*{\Huge \it Abstract}}


% Mapping brain functional connectivity from functional Magnetic Resonance Imaging (MRI) data has become
% a very active field of research. However, analysis tools are limited and many important tasks, such as the empirical
% definition of brain networks, remain difficult due to the lack of a good framework for the statistical
% modeling of these networks. We propose to develop population models of anatomical and functional connectivity
% data to improve the alignment of subjects brain structures of interest while inferring an average template
% of these structures. Based on this essential contribution, we will design new statistical inference procedures to
% compare the functional connections between conditions or populations and improve the sensitivity of connectivity
% analysis performed on noisy data. Finally, we will test and validate the methods on multiple datasets and
% distribute them to the brain imaging community.

% ...

% In many scientific fields, the data acquisition devices have benefited from hardware improvement to increase the
% resolution of the observed phenomena, leading to ever larger datasets (both in sample size $n$ and dimensionality $p$). These are the so-called ``big-data'' regimes in which
% $min(n, p) \rightarrow \infty$  and $n \ll p$ simultaneously.
% %% While the dimensionality has increased,
% %% the number of samples $n$ available is often limited, due to physical or financial limits.
% Things become instantly problematic both computationally and statistically when these
% data are processed with estimators that have a large complexity in the data size, such as
% mass-univariate models.
% In such cases, it is very useful to rely on structured priors, so that the results reflect the state of knowledge on the phenomena of interest, and we avoid sampling from empty regions of the likelihood landscape. The study of human brain activity through high-field MRI belongs to
% this class of problems.
% However, we are missing fast estimators for multivariate models for brain decoding or the study of inter-subject variability,  with structured priors, that furthermore provide statistical control on the solution.

% The goal of this PhD thesis is develop new statistical methods for studying inter-subject variability, the prime goal being to improve analysis of functional connectivity in the human brain. This naturally leads to problems related to data-driven extraction of functional atlases, and
% multivariate models for brain decoding, inter-subject registration of MRI images, 

% ...

% % \section{Plan}
% % In this report, I shall present a selection (chapters \ref{sec:spacenet}, \ref{sec:online},
% % and \ref{sec:reg}) of the work I have done during my ongoing PhD project. This selection will be
% % centered around structured penalties for brain decoding (section \ref{sec:spacenet}), and online
% % structured decomposition methods for brain data (section \ref{sec:online}).
% % We shall also discuss
% % some preliminary results on new inter-subject registration methods for functional brain data
% % (chapter \ref{sec:reg}).
% % My precise contributions w.r.t these topics will be outlined  as we proceed.
% % The report will be concluded with a synthesis of the progress made so far, and detailed plans for
% % the future.

% \vspace*{\fill}

% \clearpage

% % \newpage\null\newpage


% \vspace*{\fill}

% \tableofcontents

% \newpage

\begin{fullwidth}
% \setcounter{secnumdepth}{3}
  \setcounter{tocdepth}{3}

\dominitoc% Initialization  
\tableofcontents
\end{fullwidth}

\clearpage
{\section*{\Huge \it Notation}}
\label{sec:notations}

\textbf{XXX: Known issues:}
\begin{itemize}
\item  Cross-chapter referencing is not working
\end{itemize}


Throughout the manuscript, we shall use the following standard notation
and terminology without further explanation.
% \vspace{50pt}

\begin{fullwidth}
\def\arraystretch{1.5}
\begin{longtable}{p{2cm} | p{6cm} | p{9cm}}
% \toprule
% \multicolumn{3}{c}{Different Approaches to Ordinal Regression}\\ 
\cmidrule{1-3}
Notation & Name / synopsis & Definition\\ 
  \midrule
  $[\![k]\!]$ & Integers from $1$ to $k$ (inclusive) & $\{1,~2, \ldots,~k \}$ \\
  $\| \B{v} \|_r$ & $\ell_r$ norm for vectors in  a finite-dimensional Euclidean space & $\begin{cases}\sqrt[r]{\sum_i |v_i|^r},&\mbox{ if }1 \le r < \infty,\\\max_{i}|v_i|,&\mbox { if }r = \infty\end{cases}$ \\
  $\mathcal H$ & Arbitrary Hilbert space with norm inner product $\langle .,.\rangle_{\mathcal H}$ and norm $\v \mapsto \|\v\|_{\mathcal H} := \sqrt{\langle \v,\v\rangle_{\mathcal H}}$& Normed space containing its Cauchy limits\\
$H(X)$ & Entropy of a random variable $X \sim p_X$ & $\sum_{x}p_{X}(x)\log(p_{X}(x))$\\
$MI(X_1,X_2)$ & Mutual Information between two random variables $X_1 \sim p_{X_1}$ and $X_2 \sim p_{X_2}$ & 
$ H(X_1) - H(X_2|X_1)$\\

 $NMI(X_1,X_2)$ & Normalized Mutual Information between two random variables $X_1 \sim p_{X_1}$ and $X_2 \sim p_{X_2}$ & $I(X_1,X_2)/\sqrt{H(X_1)H(X_2)}$ \\
  % $\mathcal{N}(\mu, \sigma^2)$ & Normal distribution with mean $\mu$ and variance $\sigma$ & $p(x) = \frac{1}{\sqrt{2\pi\sigma}}
  %                                                                                            \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$\\

  $\mathbb B_{r,n}$ & Unit ball for the $\ell_r$ norm on $\mathbb R^n$ & $\{\B{x} \in \mathbb{R}^n|\|\B{x}\|_r \le 1\}$ \\
$\text{tr}(\B{A})$ & Trace of a matrix & $\sum_{i} a_{ii}$ \\  
$\langle \B{A}, \B{B}\rangle_{\text{Fro}}$ & Frobenius / Hilbert-Schmidt inner-product of two matrices $\B{A}$ and $\B{B}$  & $\text{tr}(\B{A}\B{B}^T)$\\
  $\| \B{X} \|_{\textbf{Fro}}$ & Frobenius norm of a matrix & $\sqrt{\langle \B{X}, \B{X}\rangle_{\text{Fro}}}$ \\
  $\|\B{X}\|_2$ & Spectral norm of matrix & $\sup\{\|\B{X}\B{u}\|_2 \text{ s.t } \|\B{u}\|_2 \le 1\}$ \\
  $\|\B{X}\|_{r,s}$ & Mixed-norm of matrix $\B{X} \in \mathbb R^{n \times m}$ &  $\left\|\left[\|\B{X}_1\|_r,\|\B{X}_2\|_r,\ldots,\|\B{X}_n\|_r\right]\right\|_s$ \\
$\B{I}_n$ & Identity matrix of size $n$ &  $I_{ij} = \delta_{ij}, ~\forall 1 \leq i, j \leq n$\\
$\B{1}_n$ & Vector of ones of size $n$ &  $1_{i} = 1, ~\forall 1 \geq i \geq n$ \\
$\B{X}^{\dagger}$ & Moore-Penrose pseudoinverse & Generalized inverse matrix\\
$\B{A}\otimes\B{B}$ & Kronecker product of matrices $\B{A}$ and $\B{B}$ & \\
$\B{A}\circ\B{B}$ & Outer product of matrices $\B{A}$ and $\B{B}$ & \\

$\text{vec}(\B{A})$ & Vectorization of a matrix & Concatenation of the columns of a matrix into a single giant column vector\\

%  $\mathbb{E}(X)$ & Expectation of the random variable X & $\int X dP$\\

\midrule
$i_C$ & Indicator function of $C$ & $i_C(\B{x}):= \begin{cases}0,&\mbox{ if }\B{x} \in C\\\infty,&\mbox{ otherwise}\end{cases}$\\
  $\sigma_C$ & Support function of $C$ & $\sigma_C(\B{x}) := \sup_{\B{z} \in C}\B{x}^T\B{z}$\\
  $ \dom(f)$ & Effective domain of $f: \mathcal H \rightarrow (-\infty,+\infty]$ & $\{\B{x} \in \mathbb{R}^n | f(\B{x}) < +\infty\}$ \\  
  $\partial f(x)$ & Subdifferential of $f$ at $\B{x}$ & $\partial f(\B{x}) := \{\B{v} \in \mathcal H | f(\B{z}) \ge f(\B{x}) + \B{v}^T(\B{z} - \B{x})\; \forall \B{z} \in \mathcal H\}$\\

  $\prox_f(x)$ & Proximal operator of $f$ at $\B{x}$ & $\argmin_{\B{p}}\frac{1}{2}\|\B{p}-\B{x}\|_2^2 + f(\B{p})$\\

  $\proj_C(x)$ & Orthogonal projection of $\B{x}$ onto $C$ & $\argmin_{\B{p} \in C}\frac{1}{2}\|\B{p}-\B{x}\|_2^2 = \prox_{i_C}(\B{x})$\\
  $f^*$ & Convex conjugate of $f$ & $f^*(\B{x}) := \sup_{\B{y}}\B{x}^T\B{z} - f(\B{z})$\\
  $L_F$ & Lipschitz constant of $F: \mathcal H_1 \rightarrow \mathcal H_2$ & $\inf\{C \ge 0 | \|F(\x) - F(\y)\|_{\mathcal H_2} \le C\|\x - \y\|_{\mathcal H_1}\;\forall \x,\y \in \mathcal H_1\}$ \\
  \midrule

  $\nabla $ & Discrete spatial gradient operator. This defines a linear operator from $\mathbb R^p$ to $\mathbb R^{3p}$, where $p$ is the number of voxels in the image & At a voxel $j$, the spatial gradient of an image $\B{w}$ is a vector ${\nabla } {\w}(j) := [\nabla_{x} {\w}(j), \nabla_{y} {\w}(j), \nabla_{z} {\w}(j)]$, $\forall \w \in \mathbb R^p$ \\
  
  $\Delta$ & Discrete spatial image Laplacian operator & $-\nabla ^T\nabla  \in \mathbb R^{p \times p}$\\
  $\nabla_\rho$ & The identity-augmented version of the discrete spatial gradient operator & ${\nabla_\rho} {\w} := [(1-\rho)\nabla \w, \rho \w] \in \mathbb R^{4p}$, $\forall \w \in \mathbb R^p$ \\
  $\Delta_\rho$ & Laplacian operator corresponding to the identity-augmented spatial gradient operator $\nabla_\rho$ . This defines a linear operator from $\mathbb R^p$ to $\mathbb R^{4p}$ & $\rho^2\I + (1-\rho)^2\Delta \in \mathbb R^{p \times p}$ \\
  
  $\text{Lap}(\B{w})$ & Laplacian regularization of a 3D image $\B{w}$ & $\frac{1}{2}\|\nabla \w\|_\text{Fro}^2 = \frac{1}{2}\sum_{j=1}^p(\nabla_x \B{w})_j^2 + (\nabla_y \B{w})_j^2 + (\nabla_z \B{w})_j^2$ \\ % = \frac{1}{2}{\B{v}}^T\Delta \B{v} \ge 0$
  $\|\B{w}\|_{\text{TV}}$ & Isotropic Total-Variation (TV) regularization & $\|\nabla \w\|_{2,1} =
  % \sum_{j}\|(\nabla \w)_j\|_2=
\sum_{j}\sqrt{(\nabla_x \B{w})_j^2 + (\nabla_y \B{w})_j^2 + (\nabla_z \B{w})_j^2}$\\
  $\|\B{w}\|_{\text{SV}}$ & Sparse Variation regularization & $\|\nabla_\rho \w\|_{2,1} = \sum_{j}\sqrt{\rho^2 w_j + (1-\rho)^2\|\nabla \w)_j\|_2^2}$\\  
  $\|\B{w}\|_{\text{AnisoTV}}$ & Anisotropic TV regularization & $\|\nabla \w\|_{1,1} = 
% \sum_{j}\|(\nabla \w)_j\|_1=
\sum_{j}|(\nabla_x \B{w})_j| + |(\nabla_y \B{w})_j| + |(\nabla_z \B{w})_j|$\\
  

  

 \bottomrule
\end{longtable}
\end{fullwidth}

%  $e_n=(1,1,...,1) \in
% \mathbb{R}^n$ denotes the vector of $n$ $1$'s, so that $\langle e_n,
% x\rangle = \sum_{1 \le i \le n}x_i$, the sum of the components of $x$.
% Given (abtract) sets $X$, $Y$, $Z\subseteq Y$, and a function $f: X
% \rightarrow Y$, the \textit{preimage} of $Z$ by $f$, denoted
% $f^{-1}Z$, is defined by $f^{-1}Z := \{x \in X | f(x) \in Z\}$. $\#X
% := \sum_{x \in X}1$ denotes the \textit{cardinality} of $X$ (i.e the
% number of elements it contains). The \textit{complement} of $Z$ w.r.t
% $Y$ is $Y\setminus Z := \{y \in Y|y \not\in Z\}$.

% Let $m$ and $n$ be positive integers. The $n \times n$ identity matrix
% will be denoted $I_n$ and its $i$th row is $\delta_n(i)$, an
% $n$-deimensional vector with $0$'s everywhere except at the $i$th
% coordinate where there is a $1$; for example $\delta_3(2) = (0, 1,
% 0)$. Given a vector $x \in \mathbb{R}^n$, define  subsets of
% indices $\mathcal{I}_{++}(x) := \{1 \le i \le n | x_i >
% 0\}$, $\mathcal{I}_{-}(x) := \{1,2,...,n\}\setminus\mathcal{I}_{++}$,
% $\mathcal{I}_{- -}(x) := \mathcal{I}_{++}(-x)$, and $\mathcal{I}_{+}
% := \{1,2,...,n\}\setminus\mathcal{I}_{- -}$.
% Given a subset of indices $I \subseteq \{1,2,...,n\}$, $x|_I \in
% \mathbb{R}^{|I|}$ denotes the components of $x$ restricted to these
% indices. For example
% $x|_{\mathcal{I}_{++}(x)}$ corresponds to the positive components of
% $x$. Given $X \subseteq \mathbb{R}^n$, the \textit{convex hull} of
% $X$, denoted $\conv X$, is defined to be the smallest convex subset
% of $\mathbb{R}^n$ containing $X$. For example, one has $\Delta_n =
% \conv\{\delta_n(i)| 1 \le i \le n\}$. The subset $F_n(I)
% \subseteq \Delta_n$ defined by
% \[
% F_n(I) := \conv \{\delta_n(i) | i \in
% I\}
% \]
% is called the \textit{face} of $\Delta_n$
% spanned by the vertices labelled by $I$. Geometrically, this
% corresponds to a lower-dimensional simplex with $\#I$ vertices
% labelled by $I$, and so can be conveniently identified with
% $\Delta_{\#I}$. $(x)_+:=\text{max}(0, x) \ge 0$ is the point-wise
% maximum of $x$ with $0$. For example, $((-2, \pi))_+ = (\text{max}(-2,
% 0), \text{max}(\pi, 0)) = (0, \pi)$. It's not hard to show that
% \begin{eqnarray}
% \mathrm{max}(x, y) = x + (y-x)_+ = y + (x-y)_+,
% \label{eq:maxplus}
% \end{eqnarray}
% and in particular,
% \begin{eqnarray}
% (x)_+ = x + (-x)_+.
% \end{eqnarray}
% Finally, we will adopt the convention: $0\log{0} = 0$, $\text{inf
% }\emptyset = +\infty$, and $\text{sup }\emptyset = -\infty$.

% \paragraph{Essential convex analysis.}
% Let us introduce some basic but powerful modern convex-analytical
% notions which will be essential in the sequel. Let $\|.\|$ be a norm
% on $\mathbb{R}^n$ with dual norm $\|.\|_*$ The unit
% ball in $\mathbb{R}^n$ w.r.t the norm $\|.\|$ will be denoted
% $\mathbb{B}_{n,\|.\|}$, and defined by
% \begin{eqnarray}
%   \mathbb{B}_{n,\|.\|} := \{z \in \mathbb{R}^n|\|z\| \le 1\}.
% \end{eqnarray}
% If $\|.\|$ is an $\ell_p$-norm, then we will simply write
% $\mathbb{B}_{n,p}$ for $\mathbb{B}_{n,\|.\|_p}$.
% Given a subset $C$ of $\mathbb{R}^n$, $i_C$ denotes its
% \textit{indicator function} defined by
% \begin{eqnarray}
%   i_C(x) = 0 \text{ if } x \in C\text{ and }+\infty\text{
%     otherwise,}
% \end{eqnarray}
% and $\sigma_C : s \mapsto \underset{x \in C}{\text{sup }}\langle s,
% x\rangle$ defines its \textit{support function}. As an example, it is
% an easy excercise to show that $\sigma_{\mathbb{B}_{\|.\|}} =
% \|.\|_*$.

% Let $f : \mathbb{R}^n \rightarrow (-\infty, +\infty]$ be an
%   \textit{extended real-valued} convex function. We say that $f$ is
%   closed if its \textit{epigraph}
%   \begin{eqnarray}
%     epi(f) := \{(x,t) \in \mathbb{R}^{n + 1}|t \ge f(x)\}
% \end{eqnarray}
% is closed. The \textit{effective domain} of $f$, denoted
% $\dom{f}$, is defined as
% \begin{eqnarray}
%   \dom{f} := \{x \in \mathbb{R}^n | f(x) < +\infty\}.
% \end{eqnarray}
%  If $\dom{f} \ne \emptyset$ then we say $f$ is \textit{proper}.
% $\cont{f}$ denotes the set of points at which $f$ is continuous.
% The \textit{subdifferential} of $f$ at a point $x \in \mathbb{R}^n$ is
% defined by
% \begin{eqnarray}
% \partial f(x) := \{s\in \mathbb{R}^n | f(z)  \ge f(x) + \langle s, z -
% x\rangle, \forall z \in \mathbb{R}^n\}.
% \end{eqnarray}
% Each element of $\partial f(x)$ is called a \textit{subgradient} of $f$
% at $x$. Of course $\partial f(x)$ reduces to the singleton $\{\nabla
% f(x)\}$ in case $f$ is differentiable at $x$. The \textit{convex
%   conjugate} (aka \textit{Fenchel-Legendre transform}) of $f$ is the
% function $f:\mathbb{R}^n \rightarrow (-\infty,+\infty]$ defined by
% \begin{eqnarray}
% f^*(s) := \underset{x \in \mathbb{R}^n}{\text{sup }}\langle s,
% x\rangle - f(x).
% \end{eqnarray}
% If $C$ is a closed convex subset of $\mathbb{R}^n$, then it is not
% hard to see that $i_C^* = \sigma_C$ and $\sigma_C^* = i_C$. For
% example, For example $\|.\|^* = i_{\mathbb{B}_{n,\|.\|_*}}$. 
% \begin{eqnarray}
% i_{\Delta_n}^*(s) = \sigma_{\Delta_n}(s) = \underset{x \in
%   \Delta_n}{\text{sup }}\langle s,
% x\rangle = \underset{1 \le i \le n}{\text{max }}s_i.
% \label{eq:nice_conj}
% \end{eqnarray}
% %% One has the \textit{biconjugate} inequality
% %% \[
% %% f^{**} \le f.
% %% \]
% %% Also, there is the well-known ``biconjugate theorem'' which states
% %% that $f^{**} = f$ iff $f$ is proper and closed.

% The following theorem is very useful for computing subdifferentials of
% functions of ``max-type'' (e.g of support functions), and will be
% instrumental in proving Theorem \ref{thm:l1}. It is a result
% due to D. P. Bertsekas \cite{bertsekas1971control}, which extends to
% subdifferentials, a well-known theorem of J.M Danskin, the so-called
% Danskin's theorem (see
% \cite{danskin66}, for example).

% \begin{theorem}[Danskin-Bertsekas theorem for subdifferentials]
% Let $\phi: \mathbb{R}^m \times \mathbb{R}^n \rightarrow (-\infty,
% +\infty]$ be a function and $X$ be a nonempty compact subset of
%   $\mathbb{R}^n$. Assume further that for every $x \in X$, the function $\phi(., x) :
%   \mathbb{R}^m \rightarrow (-\infty, +\infty]$ is a
%     closed  proper convex function. Consider the function $f:
%     \mathbb{R}^n \rightarrow (-\infty, +\infty]$ defined by
% \[
% f(s) := \underset{x \in X}{\text{sup }}\phi(s, x).
% \]
% If $f$ is finite somewhere, then it is a closed proper convex
% function. Furthermore, if $\inte\dom f \ne \emptyset$ and $\phi$ is
% continuous on $\inte\dom f \times X$, then for every $s \in \inte\dom
% f$ the subdifferential of $f$ at $s$ is given by
% \begin{eqnarray}
% \partial f(s) = \conv\{\partial \phi(s, \hat{x})|\hat{x} \in \hat{X}(s)\},
% \end{eqnarray}
% where $\hat{X}(s) := \{x \in X|\phi(s, x) = f(s)\}$.
% \label{thm:danskin}
% \end{theorem}
% \begin{proof}
% See \cite[Proposition A.22]{bertsekas1971control}.
% \end{proof}

% \listoffigures
% \listoftables

% \listofalgorithms
\addtocontents{loa}{\def\string\figurename{Algorithm}}

 \part{\Huge{Introduction}}
\include{abstract}

\part{\Huge{Multi-variate priors for analyzing brain data: models and algorithms}}
\include{chapter_2/chapter_2} % SpaceNet model

\include{chapter_3/chapter_3} % SpaceNet algos
\include{chapter_10/chapter_10} % SpaceNet algos

\include{chapter_7/chapter_7} % iGraphNet
\include{chapter_8/chapter_8} % ADMM

\part{\Huge{Functional inter-subject variability}}
\include{chapter_1/chapter_1}  % EPI-to-EPI

% \part{Predicting individual functional differences using resting-state fMRI}
\include{chapter_4/chapter_4} % Smooth sparse DL
\include{chapter_9/chapter_9} % proximal dict learning
\include{chapter_5/chapter_5} % From rsfMRI to tfMRI

\part{\Huge{Conclusion}}
\include{chapter_6/chapter_6} % Conclusion
\include{appendix_1}
\printglossaries

% \begin{fullwidth}
% \bibliographystyle{plainnat}
% \bibliography{bib.bib}
% \end{fullwidth}

\end{document}